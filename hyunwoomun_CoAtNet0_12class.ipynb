{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_cv_attention_models in /root/anaconda3/lib/python3.8/site-packages (1.2.27)\n",
      "Requirement already satisfied: tensorflow in /root/anaconda3/lib/python3.8/site-packages (from keras_cv_attention_models) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-datasets in /root/anaconda3/lib/python3.8/site-packages (from keras_cv_attention_models) (4.6.0)\n",
      "Requirement already satisfied: tensorflow-addons in /root/anaconda3/lib/python3.8/site-packages (from keras_cv_attention_models) (0.17.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.46.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (3.3.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (3.19.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (0.26.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.20.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.15.0)\n",
      "Requirement already satisfied: packaging in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (20.9)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (52.0.0.post20210125)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow->keras_cv_attention_models) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->keras_cv_attention_models) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (2.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/anaconda3/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (3.3.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /root/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /root/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_cv_attention_models) (3.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /root/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow->keras_cv_attention_models) (2.4.7)\n",
      "Requirement already satisfied: typeguard>=2.7 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-addons->keras_cv_attention_models) (2.13.3)\n",
      "Requirement already satisfied: tqdm in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (4.59.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (1.8.0)\n",
      "Requirement already satisfied: etils[epath] in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.6.0)\n",
      "Requirement already satisfied: dill in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.3.5.1)\n",
      "Requirement already satisfied: promise in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (2.3)\n",
      "Requirement already satisfied: toml in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.10.2)\n",
      "Requirement already satisfied: importlib-resources in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->keras_cv_attention_models) (5.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /root/anaconda3/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv_attention_models) (1.56.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_cv_attention_models import coatnet\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36720 images belonging to 12 classes.\n",
      "Found 12240 images belonging to 12 classes.\n",
      "Found 12240 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "class_num = 12\n",
    "batch_size = 32\n",
    "target_size=(200,200)\n",
    "\n",
    "gen = ImageDataGenerator(rescale=1/255.)\n",
    "train_gen = gen.flow_from_directory('./data/train/', target_size=target_size, class_mode='categorical', batch_size=batch_size, shuffle=True)\n",
    "valid_gen = gen.flow_from_directory('./data/valid/', target_size=target_size, class_mode='categorical', batch_size=batch_size, shuffle=True)\n",
    "test_gen = gen.flow_from_directory('./data/test/', target_size=target_size, class_mode='categorical', batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: /root/.keras/models/coatnet0_224_imagenet.h5\n",
      "WARNING:tensorflow:Skipping loading weights for layer #102 (named stack_3_block_1_mhsa_pos_emb) due to mismatch in shape for weight stack_3_block_1_mhsa_pos_emb/positional_embedding:0. Weight expects shape (6, 625). Received saved weight with shape (6, 729)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #128 (named stack_3_block_2_mhsa_pos_emb) due to mismatch in shape for weight stack_3_block_2_mhsa_pos_emb/positional_embedding:0. Weight expects shape (12, 625). Received saved weight with shape (12, 729)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #152 (named stack_3_block_3_mhsa_pos_emb) due to mismatch in shape for weight stack_3_block_3_mhsa_pos_emb/positional_embedding:0. Weight expects shape (12, 625). Received saved weight with shape (12, 729)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #176 (named stack_3_block_4_mhsa_pos_emb) due to mismatch in shape for weight stack_3_block_4_mhsa_pos_emb/positional_embedding:0. Weight expects shape (12, 625). Received saved weight with shape (12, 729)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #200 (named stack_3_block_5_mhsa_pos_emb) due to mismatch in shape for weight stack_3_block_5_mhsa_pos_emb/positional_embedding:0. Weight expects shape (12, 625). Received saved weight with shape (12, 729)\n",
      ">>>> Reload mismatched weights: 224 -> (200, 200)\n",
      ">>>> Reload layer: stack_3_block_1_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_3_block_2_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_3_block_3_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_3_block_4_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_3_block_5_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_4_block_1_mhsa_pos_emb\n",
      ">>>> Reload layer: stack_4_block_2_mhsa_pos_emb\n",
      "Model: \"coatnet0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " stem_1_pad (ZeroPadding2D)     (None, 202, 202, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " stem_1_conv (Conv2D)           (None, 100, 100, 64  1728        ['stem_1_pad[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_1_bn (BatchNormalization)  (None, 100, 100, 64  256        ['stem_1_conv[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_1_gelu (Activation)       (None, 100, 100, 64  0           ['stem_1_bn[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_2_pad (ZeroPadding2D)     (None, 102, 102, 64  0           ['stem_1_gelu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_2_conv (Conv2D)           (None, 100, 100, 64  36864       ['stem_2_pad[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stack_1_block_1_preact_bn (Bat  (None, 100, 100, 64  256        ['stem_2_conv[0][0]']            \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " stack_1_block_1_expand_conv (C  (None, 100, 100, 25  16384      ['stack_1_block_1_preact_bn[0][0]\n",
      " onv2D)                         6)                               ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1_expand_bn (Bat  (None, 100, 100, 25  1024       ['stack_1_block_1_expand_conv[0][\n",
      " chNormalization)               6)                               0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block_1_expand_gelu (A  (None, 100, 100, 25  0          ['stack_1_block_1_expand_bn[0][0]\n",
      " ctivation)                     6)                               ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1_MB_dw_pad (Zer  (None, 102, 102, 25  0          ['stack_1_block_1_expand_gelu[0][\n",
      " oPadding2D)                    6)                               0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block_1_MB_dw_conv (De  (None, 50, 50, 256)  2304       ['stack_1_block_1_MB_dw_pad[0][0]\n",
      " pthwiseConv2D)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1_MB_dw_bn (Batc  (None, 50, 50, 256)  1024       ['stack_1_block_1_MB_dw_conv[0][0\n",
      " hNormalization)                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_1_MB_dw_gelu (Ac  (None, 50, 50, 256)  0          ['stack_1_block_1_MB_dw_bn[0][0]'\n",
      " tivation)                                                       ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 1, 1, 256)   0           ['stack_1_block_1_MB_dw_gelu[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_1_se_1_conv (Con  (None, 1, 1, 16)    4112        ['tf.math.reduce_mean[0][0]']    \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block_1_se_gelu (Activ  (None, 1, 1, 16)    0           ['stack_1_block_1_se_1_conv[0][0]\n",
      " ation)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1_se_2_conv (Con  (None, 1, 1, 256)   4352        ['stack_1_block_1_se_gelu[0][0]']\n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block_1_se_sigmoid (Ac  (None, 1, 1, 256)   0           ['stack_1_block_1_se_2_conv[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1_shortcut_pool   (None, 50, 50, 64)  0           ['stem_2_conv[0][0]']            \n",
      " (MaxPooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " stack_1_block_1_se_out (Multip  (None, 50, 50, 256)  0          ['stack_1_block_1_MB_dw_gelu[0][0\n",
      " ly)                                                             ]',                              \n",
      "                                                                  'stack_1_block_1_se_sigmoid[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_1_shortcut_conv   (None, 50, 50, 96)  6144        ['stack_1_block_1_shortcut_pool[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " stack_1_block_1_MB_pw_conv (Co  (None, 50, 50, 96)  24576       ['stack_1_block_1_se_out[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " stack_1_block_1_output (Add)   (None, 50, 50, 96)   0           ['stack_1_block_1_shortcut_conv[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'stack_1_block_1_MB_pw_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_2_preact_bn (Bat  (None, 50, 50, 96)  384         ['stack_1_block_1_output[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stack_1_block_2_expand_conv (C  (None, 50, 50, 384)  36864      ['stack_1_block_2_preact_bn[0][0]\n",
      " onv2D)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2_expand_bn (Bat  (None, 50, 50, 384)  1536       ['stack_1_block_2_expand_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block_2_expand_gelu (A  (None, 50, 50, 384)  0          ['stack_1_block_2_expand_bn[0][0]\n",
      " ctivation)                                                      ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2_MB_dw_pad (Zer  (None, 52, 52, 384)  0          ['stack_1_block_2_expand_gelu[0][\n",
      " oPadding2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block_2_MB_dw_conv (De  (None, 50, 50, 384)  3456       ['stack_1_block_2_MB_dw_pad[0][0]\n",
      " pthwiseConv2D)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2_MB_dw_bn (Batc  (None, 50, 50, 384)  1536       ['stack_1_block_2_MB_dw_conv[0][0\n",
      " hNormalization)                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_2_MB_dw_gelu (Ac  (None, 50, 50, 384)  0          ['stack_1_block_2_MB_dw_bn[0][0]'\n",
      " tivation)                                                       ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 1, 1, 384)   0           ['stack_1_block_2_MB_dw_gelu[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_2_se_1_conv (Con  (None, 1, 1, 24)    9240        ['tf.math.reduce_mean_1[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block_2_se_gelu (Activ  (None, 1, 1, 24)    0           ['stack_1_block_2_se_1_conv[0][0]\n",
      " ation)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2_se_2_conv (Con  (None, 1, 1, 384)   9600        ['stack_1_block_2_se_gelu[0][0]']\n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block_2_se_sigmoid (Ac  (None, 1, 1, 384)   0           ['stack_1_block_2_se_2_conv[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2_se_out (Multip  (None, 50, 50, 384)  0          ['stack_1_block_2_MB_dw_gelu[0][0\n",
      " ly)                                                             ]',                              \n",
      "                                                                  'stack_1_block_2_se_sigmoid[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_1_block_2_MB_pw_conv (Co  (None, 50, 50, 96)  36864       ['stack_1_block_2_se_out[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " stack_1_block_2_output (Add)   (None, 50, 50, 96)   0           ['stack_1_block_1_output[0][0]', \n",
      "                                                                  'stack_1_block_2_MB_pw_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_1_preact_bn (Bat  (None, 50, 50, 96)  384         ['stack_1_block_2_output[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stack_2_block_1_expand_conv (C  (None, 50, 50, 384)  36864      ['stack_2_block_1_preact_bn[0][0]\n",
      " onv2D)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1_expand_bn (Bat  (None, 50, 50, 384)  1536       ['stack_2_block_1_expand_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_1_expand_gelu (A  (None, 50, 50, 384)  0          ['stack_2_block_1_expand_bn[0][0]\n",
      " ctivation)                                                      ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1_MB_dw_pad (Zer  (None, 52, 52, 384)  0          ['stack_2_block_1_expand_gelu[0][\n",
      " oPadding2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_1_MB_dw_conv (De  (None, 25, 25, 384)  3456       ['stack_2_block_1_MB_dw_pad[0][0]\n",
      " pthwiseConv2D)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1_MB_dw_bn (Batc  (None, 25, 25, 384)  1536       ['stack_2_block_1_MB_dw_conv[0][0\n",
      " hNormalization)                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_1_MB_dw_gelu (Ac  (None, 25, 25, 384)  0          ['stack_2_block_1_MB_dw_bn[0][0]'\n",
      " tivation)                                                       ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 1, 1, 384)   0           ['stack_2_block_1_MB_dw_gelu[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_1_se_1_conv (Con  (None, 1, 1, 24)    9240        ['tf.math.reduce_mean_2[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_1_se_gelu (Activ  (None, 1, 1, 24)    0           ['stack_2_block_1_se_1_conv[0][0]\n",
      " ation)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1_se_2_conv (Con  (None, 1, 1, 384)   9600        ['stack_2_block_1_se_gelu[0][0]']\n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_1_se_sigmoid (Ac  (None, 1, 1, 384)   0           ['stack_2_block_1_se_2_conv[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1_shortcut_pool   (None, 25, 25, 96)  0           ['stack_1_block_2_output[0][0]'] \n",
      " (MaxPooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " stack_2_block_1_se_out (Multip  (None, 25, 25, 384)  0          ['stack_2_block_1_MB_dw_gelu[0][0\n",
      " ly)                                                             ]',                              \n",
      "                                                                  'stack_2_block_1_se_sigmoid[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_1_shortcut_conv   (None, 25, 25, 192)  18432      ['stack_2_block_1_shortcut_pool[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " stack_2_block_1_MB_pw_conv (Co  (None, 25, 25, 192)  73728      ['stack_2_block_1_se_out[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " stack_2_block_1_output (Add)   (None, 25, 25, 192)  0           ['stack_2_block_1_shortcut_conv[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'stack_2_block_1_MB_pw_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_2_preact_bn (Bat  (None, 25, 25, 192)  768        ['stack_2_block_1_output[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stack_2_block_2_expand_conv (C  (None, 25, 25, 768)  147456     ['stack_2_block_2_preact_bn[0][0]\n",
      " onv2D)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2_expand_bn (Bat  (None, 25, 25, 768)  3072       ['stack_2_block_2_expand_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_2_expand_gelu (A  (None, 25, 25, 768)  0          ['stack_2_block_2_expand_bn[0][0]\n",
      " ctivation)                                                      ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2_MB_dw_pad (Zer  (None, 27, 27, 768)  0          ['stack_2_block_2_expand_gelu[0][\n",
      " oPadding2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_2_MB_dw_conv (De  (None, 25, 25, 768)  6912       ['stack_2_block_2_MB_dw_pad[0][0]\n",
      " pthwiseConv2D)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2_MB_dw_bn (Batc  (None, 25, 25, 768)  3072       ['stack_2_block_2_MB_dw_conv[0][0\n",
      " hNormalization)                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_2_MB_dw_gelu (Ac  (None, 25, 25, 768)  0          ['stack_2_block_2_MB_dw_bn[0][0]'\n",
      " tivation)                                                       ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 1, 1, 768)   0           ['stack_2_block_2_MB_dw_gelu[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_2_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_3[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_2_se_gelu (Activ  (None, 1, 1, 48)    0           ['stack_2_block_2_se_1_conv[0][0]\n",
      " ation)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2_se_2_conv (Con  (None, 1, 1, 768)   37632       ['stack_2_block_2_se_gelu[0][0]']\n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_2_se_sigmoid (Ac  (None, 1, 1, 768)   0           ['stack_2_block_2_se_2_conv[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2_se_out (Multip  (None, 25, 25, 768)  0          ['stack_2_block_2_MB_dw_gelu[0][0\n",
      " ly)                                                             ]',                              \n",
      "                                                                  'stack_2_block_2_se_sigmoid[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_2_MB_pw_conv (Co  (None, 25, 25, 192)  147456     ['stack_2_block_2_se_out[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " stack_2_block_2_output (Add)   (None, 25, 25, 192)  0           ['stack_2_block_1_output[0][0]', \n",
      "                                                                  'stack_2_block_2_MB_pw_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_3_preact_bn (Bat  (None, 25, 25, 192)  768        ['stack_2_block_2_output[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stack_2_block_3_expand_conv (C  (None, 25, 25, 768)  147456     ['stack_2_block_3_preact_bn[0][0]\n",
      " onv2D)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_3_expand_bn (Bat  (None, 25, 25, 768)  3072       ['stack_2_block_3_expand_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_3_expand_gelu (A  (None, 25, 25, 768)  0          ['stack_2_block_3_expand_bn[0][0]\n",
      " ctivation)                                                      ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_3_MB_dw_pad (Zer  (None, 27, 27, 768)  0          ['stack_2_block_3_expand_gelu[0][\n",
      " oPadding2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block_3_MB_dw_conv (De  (None, 25, 25, 768)  6912       ['stack_2_block_3_MB_dw_pad[0][0]\n",
      " pthwiseConv2D)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_3_MB_dw_bn (Batc  (None, 25, 25, 768)  3072       ['stack_2_block_3_MB_dw_conv[0][0\n",
      " hNormalization)                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_3_MB_dw_gelu (Ac  (None, 25, 25, 768)  0          ['stack_2_block_3_MB_dw_bn[0][0]'\n",
      " tivation)                                                       ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None, 1, 1, 768)   0           ['stack_2_block_3_MB_dw_gelu[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_3_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_4[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_3_se_gelu (Activ  (None, 1, 1, 48)    0           ['stack_2_block_3_se_1_conv[0][0]\n",
      " ation)                                                          ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_3_se_2_conv (Con  (None, 1, 1, 768)   37632       ['stack_2_block_3_se_gelu[0][0]']\n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_3_se_sigmoid (Ac  (None, 1, 1, 768)   0           ['stack_2_block_3_se_2_conv[0][0]\n",
      " tivation)                                                       ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_3_se_out (Multip  (None, 25, 25, 768)  0          ['stack_2_block_3_MB_dw_gelu[0][0\n",
      " ly)                                                             ]',                              \n",
      "                                                                  'stack_2_block_3_se_sigmoid[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_2_block_3_MB_pw_conv (Co  (None, 25, 25, 192)  147456     ['stack_2_block_3_se_out[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " stack_2_block_3_output (Add)   (None, 25, 25, 192)  0           ['stack_2_block_2_output[0][0]', \n",
      "                                                                  'stack_2_block_3_MB_pw_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_1_preact_ln (Lay  (None, 25, 25, 192)  384        ['stack_2_block_3_output[0][0]'] \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stack_3_block_1_pool (MaxPooli  (None, 13, 13, 192)  0          ['stack_3_block_1_preact_ln[0][0]\n",
      " ng2D)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1_mhsa_qkv_conv   (None, 13, 13, 576)  110592     ['stack_3_block_1_pool[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 169, 576)     0           ['stack_3_block_1_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 169, 192),   0           ['tf.reshape[0][0]']             \n",
      "                                 (None, 169, 192),                                                \n",
      "                                 (None, 169, 192)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 169, 6, 32)   0           ['tf.split[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 169, 6, 32)   0           ['tf.split[0][1]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 6, 169, 32)  0           ['tf.reshape_1[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 6, 32, 169)  0           ['tf.reshape_2[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 6, 169, 169)  0           ['tf.compat.v1.transpose[0][0]', \n",
      "                                                                  'tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 6, 169, 169)  0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " stack_3_block_1_mhsa_pos_emb (  (None, 6, 169, 169)  3750       ['tf.math.multiply[0][0]']       \n",
      " MultiHeadRelativePositionalEmb                                                                   \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 169, 6, 32)   0           ['tf.split[0][2]']               \n",
      "                                                                                                  \n",
      " stack_3_block_1_mhsa_attention  (None, 6, 169, 169)  0          ['stack_3_block_1_mhsa_pos_emb[0]\n",
      " _scores (Softmax)                                               [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (TFOp  (None, 6, 169, 32)  0           ['tf.reshape_3[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 6, 169, 32)   0           ['stack_3_block_1_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (TFOp  (None, 169, 6, 32)  0           ['lambda_1[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " stack_3_block_1_shortcut_pool   (None, 13, 13, 192)  0          ['stack_2_block_3_output[0][0]'] \n",
      " (MaxPooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)      (None, 13, 13, 192)  0           ['tf.compat.v1.transpose_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_1_shortcut_conv   (None, 13, 13, 384)  73728      ['stack_3_block_1_shortcut_pool[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_1_mhsa_output (D  (None, 13, 13, 384)  73728      ['tf.reshape_4[0][0]']           \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_1_output (Add)   (None, 13, 13, 384)  0           ['stack_3_block_1_shortcut_conv[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'stack_3_block_1_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block_1_ffn_preact_ln   (None, 13, 13, 384)  768        ['stack_3_block_1_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_1_ffn_1_conv (Co  (None, 13, 13, 1536  589824     ['stack_3_block_1_ffn_preact_ln[0\n",
      " nv2D)                          )                                ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_1_ffn_gelu (Acti  (None, 13, 13, 1536  0          ['stack_3_block_1_ffn_1_conv[0][0\n",
      " vation)                        )                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_1_ffn_2_conv (Co  (None, 13, 13, 384)  589824     ['stack_3_block_1_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_1_ffn_output (Ad  (None, 13, 13, 384)  0          ['stack_3_block_1_output[0][0]', \n",
      " d)                                                               'stack_3_block_1_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_2_preact_ln (Lay  (None, 13, 13, 384)  768        ['stack_3_block_1_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_2_mhsa_qkv_conv   (None, 13, 13, 1152  442368     ['stack_3_block_2_preact_ln[0][0]\n",
      " (Conv2D)                       )                                ']                               \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)      (None, 169, 1152)    0           ['stack_3_block_2_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)        [(None, 169, 384),   0           ['tf.reshape_5[0][0]']           \n",
      "                                 (None, 169, 384),                                                \n",
      "                                 (None, 169, 384)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)      (None, 169, 12, 32)  0           ['tf.split_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_7 (TFOpLambda)      (None, 169, 12, 32)  0           ['tf.split_1[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_4 (TFOp  (None, 12, 169, 32)  0          ['tf.reshape_6[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_5 (TFOp  (None, 12, 32, 169)  0          ['tf.reshape_7[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 12, 169, 169  0           ['tf.compat.v1.transpose_4[0][0]'\n",
      "                                )                                , 'tf.compat.v1.transpose_5[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 12, 169, 169  0          ['lambda_2[0][0]']               \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " stack_3_block_2_mhsa_pos_emb (  (None, 12, 169, 169  7500       ['tf.math.multiply_1[0][0]']     \n",
      " MultiHeadRelativePositionalEmb  )                                                                \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_8 (TFOpLambda)      (None, 169, 12, 32)  0           ['tf.split_1[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_2_mhsa_attention  (None, 12, 169, 169  0          ['stack_3_block_2_mhsa_pos_emb[0]\n",
      " _scores (Softmax)              )                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_6 (TFOp  (None, 12, 169, 32)  0          ['tf.reshape_8[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 12, 169, 32)  0           ['stack_3_block_2_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_6[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_7 (TFOp  (None, 169, 12, 32)  0          ['lambda_3[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_9 (TFOpLambda)      (None, 13, 13, 384)  0           ['tf.compat.v1.transpose_7[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_2_mhsa_output (D  (None, 13, 13, 384)  147456     ['tf.reshape_9[0][0]']           \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_2_output (Add)   (None, 13, 13, 384)  0           ['stack_3_block_1_ffn_output[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'stack_3_block_2_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block_2_ffn_preact_ln   (None, 13, 13, 384)  768        ['stack_3_block_2_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_2_ffn_1_conv (Co  (None, 13, 13, 1536  589824     ['stack_3_block_2_ffn_preact_ln[0\n",
      " nv2D)                          )                                ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_2_ffn_gelu (Acti  (None, 13, 13, 1536  0          ['stack_3_block_2_ffn_1_conv[0][0\n",
      " vation)                        )                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_2_ffn_2_conv (Co  (None, 13, 13, 384)  589824     ['stack_3_block_2_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_2_ffn_output (Ad  (None, 13, 13, 384)  0          ['stack_3_block_2_output[0][0]', \n",
      " d)                                                               'stack_3_block_2_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_3_preact_ln (Lay  (None, 13, 13, 384)  768        ['stack_3_block_2_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_3_mhsa_qkv_conv   (None, 13, 13, 1152  442368     ['stack_3_block_3_preact_ln[0][0]\n",
      " (Conv2D)                       )                                ']                               \n",
      "                                                                                                  \n",
      " tf.reshape_10 (TFOpLambda)     (None, 169, 1152)    0           ['stack_3_block_3_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)        [(None, 169, 384),   0           ['tf.reshape_10[0][0]']          \n",
      "                                 (None, 169, 384),                                                \n",
      "                                 (None, 169, 384)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_11 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_12 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_2[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_8 (TFOp  (None, 12, 169, 32)  0          ['tf.reshape_11[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_9 (TFOp  (None, 12, 32, 169)  0          ['tf.reshape_12[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 12, 169, 169  0           ['tf.compat.v1.transpose_8[0][0]'\n",
      "                                )                                , 'tf.compat.v1.transpose_9[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 12, 169, 169  0          ['lambda_4[0][0]']               \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " stack_3_block_3_mhsa_pos_emb (  (None, 12, 169, 169  7500       ['tf.math.multiply_2[0][0]']     \n",
      " MultiHeadRelativePositionalEmb  )                                                                \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_13 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_2[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_3_mhsa_attention  (None, 12, 169, 169  0          ['stack_3_block_3_mhsa_pos_emb[0]\n",
      " _scores (Softmax)              )                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_10 (TFO  (None, 12, 169, 32)  0          ['tf.reshape_13[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 12, 169, 32)  0           ['stack_3_block_3_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_10[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_11 (TFO  (None, 169, 12, 32)  0          ['lambda_5[0][0]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_14 (TFOpLambda)     (None, 13, 13, 384)  0           ['tf.compat.v1.transpose_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3_mhsa_output (D  (None, 13, 13, 384)  147456     ['tf.reshape_14[0][0]']          \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_3_output (Add)   (None, 13, 13, 384)  0           ['stack_3_block_2_ffn_output[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'stack_3_block_3_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block_3_ffn_preact_ln   (None, 13, 13, 384)  768        ['stack_3_block_3_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_3_ffn_1_conv (Co  (None, 13, 13, 1536  589824     ['stack_3_block_3_ffn_preact_ln[0\n",
      " nv2D)                          )                                ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_3_ffn_gelu (Acti  (None, 13, 13, 1536  0          ['stack_3_block_3_ffn_1_conv[0][0\n",
      " vation)                        )                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_3_ffn_2_conv (Co  (None, 13, 13, 384)  589824     ['stack_3_block_3_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_3_ffn_output (Ad  (None, 13, 13, 384)  0          ['stack_3_block_3_output[0][0]', \n",
      " d)                                                               'stack_3_block_3_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4_preact_ln (Lay  (None, 13, 13, 384)  768        ['stack_3_block_3_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4_mhsa_qkv_conv   (None, 13, 13, 1152  442368     ['stack_3_block_4_preact_ln[0][0]\n",
      " (Conv2D)                       )                                ']                               \n",
      "                                                                                                  \n",
      " tf.reshape_15 (TFOpLambda)     (None, 169, 1152)    0           ['stack_3_block_4_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_3 (TFOpLambda)        [(None, 169, 384),   0           ['tf.reshape_15[0][0]']          \n",
      "                                 (None, 169, 384),                                                \n",
      "                                 (None, 169, 384)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_16 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_17 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_3[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_12 (TFO  (None, 12, 169, 32)  0          ['tf.reshape_16[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_13 (TFO  (None, 12, 32, 169)  0          ['tf.reshape_17[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 12, 169, 169  0           ['tf.compat.v1.transpose_12[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'tf.compat.v1.transpose_13[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 12, 169, 169  0          ['lambda_6[0][0]']               \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " stack_3_block_4_mhsa_pos_emb (  (None, 12, 169, 169  7500       ['tf.math.multiply_3[0][0]']     \n",
      " MultiHeadRelativePositionalEmb  )                                                                \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_18 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_3[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_4_mhsa_attention  (None, 12, 169, 169  0          ['stack_3_block_4_mhsa_pos_emb[0]\n",
      " _scores (Softmax)              )                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_14 (TFO  (None, 12, 169, 32)  0          ['tf.reshape_18[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 12, 169, 32)  0           ['stack_3_block_4_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_14[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_15 (TFO  (None, 169, 12, 32)  0          ['lambda_7[0][0]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_19 (TFOpLambda)     (None, 13, 13, 384)  0           ['tf.compat.v1.transpose_15[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_4_mhsa_output (D  (None, 13, 13, 384)  147456     ['tf.reshape_19[0][0]']          \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_4_output (Add)   (None, 13, 13, 384)  0           ['stack_3_block_3_ffn_output[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'stack_3_block_4_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block_4_ffn_preact_ln   (None, 13, 13, 384)  768        ['stack_3_block_4_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_4_ffn_1_conv (Co  (None, 13, 13, 1536  589824     ['stack_3_block_4_ffn_preact_ln[0\n",
      " nv2D)                          )                                ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_4_ffn_gelu (Acti  (None, 13, 13, 1536  0          ['stack_3_block_4_ffn_1_conv[0][0\n",
      " vation)                        )                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4_ffn_2_conv (Co  (None, 13, 13, 384)  589824     ['stack_3_block_4_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_4_ffn_output (Ad  (None, 13, 13, 384)  0          ['stack_3_block_4_output[0][0]', \n",
      " d)                                                               'stack_3_block_4_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5_preact_ln (Lay  (None, 13, 13, 384)  768        ['stack_3_block_4_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5_mhsa_qkv_conv   (None, 13, 13, 1152  442368     ['stack_3_block_5_preact_ln[0][0]\n",
      " (Conv2D)                       )                                ']                               \n",
      "                                                                                                  \n",
      " tf.reshape_20 (TFOpLambda)     (None, 169, 1152)    0           ['stack_3_block_5_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)        [(None, 169, 384),   0           ['tf.reshape_20[0][0]']          \n",
      "                                 (None, 169, 384),                                                \n",
      "                                 (None, 169, 384)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_21 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_22 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_4[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_16 (TFO  (None, 12, 169, 32)  0          ['tf.reshape_21[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_17 (TFO  (None, 12, 32, 169)  0          ['tf.reshape_22[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 12, 169, 169  0           ['tf.compat.v1.transpose_16[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'tf.compat.v1.transpose_17[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 12, 169, 169  0          ['lambda_8[0][0]']               \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " stack_3_block_5_mhsa_pos_emb (  (None, 12, 169, 169  7500       ['tf.math.multiply_4[0][0]']     \n",
      " MultiHeadRelativePositionalEmb  )                                                                \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_23 (TFOpLambda)     (None, 169, 12, 32)  0           ['tf.split_4[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_5_mhsa_attention  (None, 12, 169, 169  0          ['stack_3_block_5_mhsa_pos_emb[0]\n",
      " _scores (Softmax)              )                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_18 (TFO  (None, 12, 169, 32)  0          ['tf.reshape_23[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 12, 169, 32)  0           ['stack_3_block_5_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_18[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_19 (TFO  (None, 169, 12, 32)  0          ['lambda_9[0][0]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_24 (TFOpLambda)     (None, 13, 13, 384)  0           ['tf.compat.v1.transpose_19[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_5_mhsa_output (D  (None, 13, 13, 384)  147456     ['tf.reshape_24[0][0]']          \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_5_output (Add)   (None, 13, 13, 384)  0           ['stack_3_block_4_ffn_output[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'stack_3_block_5_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block_5_ffn_preact_ln   (None, 13, 13, 384)  768        ['stack_3_block_5_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_5_ffn_1_conv (Co  (None, 13, 13, 1536  589824     ['stack_3_block_5_ffn_preact_ln[0\n",
      " nv2D)                          )                                ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_5_ffn_gelu (Acti  (None, 13, 13, 1536  0          ['stack_3_block_5_ffn_1_conv[0][0\n",
      " vation)                        )                                ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5_ffn_2_conv (Co  (None, 13, 13, 384)  589824     ['stack_3_block_5_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_3_block_5_ffn_output (Ad  (None, 13, 13, 384)  0          ['stack_3_block_5_output[0][0]', \n",
      " d)                                                               'stack_3_block_5_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_1_preact_ln (Lay  (None, 13, 13, 384)  768        ['stack_3_block_5_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_1_pool (MaxPooli  (None, 7, 7, 384)   0           ['stack_4_block_1_preact_ln[0][0]\n",
      " ng2D)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack_4_block_1_mhsa_qkv_conv   (None, 7, 7, 1152)  442368      ['stack_4_block_1_pool[0][0]']   \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_25 (TFOpLambda)     (None, 49, 1152)     0           ['stack_4_block_1_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_5 (TFOpLambda)        [(None, 49, 384),    0           ['tf.reshape_25[0][0]']          \n",
      "                                 (None, 49, 384),                                                 \n",
      "                                 (None, 49, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_26 (TFOpLambda)     (None, 49, 12, 32)   0           ['tf.split_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_27 (TFOpLambda)     (None, 49, 12, 32)   0           ['tf.split_5[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_20 (TFO  (None, 12, 49, 32)  0           ['tf.reshape_26[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_21 (TFO  (None, 12, 32, 49)  0           ['tf.reshape_27[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 12, 49, 49)   0           ['tf.compat.v1.transpose_20[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'tf.compat.v1.transpose_21[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 12, 49, 49)  0           ['lambda_10[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_4_block_1_mhsa_pos_emb (  (None, 12, 49, 49)  2028        ['tf.math.multiply_5[0][0]']     \n",
      " MultiHeadRelativePositionalEmb                                                                   \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_28 (TFOpLambda)     (None, 49, 12, 32)   0           ['tf.split_5[0][2]']             \n",
      "                                                                                                  \n",
      " stack_4_block_1_mhsa_attention  (None, 12, 49, 49)  0           ['stack_4_block_1_mhsa_pos_emb[0]\n",
      " _scores (Softmax)                                               [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_22 (TFO  (None, 12, 49, 32)  0           ['tf.reshape_28[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 12, 49, 32)   0           ['stack_4_block_1_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_22[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_23 (TFO  (None, 49, 12, 32)  0           ['lambda_11[0][0]']              \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " stack_4_block_1_shortcut_pool   (None, 7, 7, 384)   0           ['stack_3_block_5_ffn_output[0][0\n",
      " (MaxPooling2D)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_29 (TFOpLambda)     (None, 7, 7, 384)    0           ['tf.compat.v1.transpose_23[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block_1_shortcut_conv   (None, 7, 7, 768)   294912      ['stack_4_block_1_shortcut_pool[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_1_mhsa_output (D  (None, 7, 7, 768)   294912      ['tf.reshape_29[0][0]']          \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_4_block_1_output (Add)   (None, 7, 7, 768)    0           ['stack_4_block_1_shortcut_conv[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'stack_4_block_1_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block_1_ffn_preact_ln   (None, 7, 7, 768)   1536        ['stack_4_block_1_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block_1_ffn_1_conv (Co  (None, 7, 7, 3072)  2359296     ['stack_4_block_1_ffn_preact_ln[0\n",
      " nv2D)                                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_1_ffn_gelu (Acti  (None, 7, 7, 3072)  0           ['stack_4_block_1_ffn_1_conv[0][0\n",
      " vation)                                                         ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_1_ffn_2_conv (Co  (None, 7, 7, 768)   2359296     ['stack_4_block_1_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_4_block_1_ffn_output (Ad  (None, 7, 7, 768)   0           ['stack_4_block_1_output[0][0]', \n",
      " d)                                                               'stack_4_block_1_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_2_preact_ln (Lay  (None, 7, 7, 768)   1536        ['stack_4_block_1_ffn_output[0][0\n",
      " erNormalization)                                                ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_2_mhsa_qkv_conv   (None, 7, 7, 2304)  1769472     ['stack_4_block_2_preact_ln[0][0]\n",
      " (Conv2D)                                                        ']                               \n",
      "                                                                                                  \n",
      " tf.reshape_30 (TFOpLambda)     (None, 49, 2304)     0           ['stack_4_block_2_mhsa_qkv_conv[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " tf.split_6 (TFOpLambda)        [(None, 49, 768),    0           ['tf.reshape_30[0][0]']          \n",
      "                                 (None, 49, 768),                                                 \n",
      "                                 (None, 49, 768)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_31 (TFOpLambda)     (None, 49, 24, 32)   0           ['tf.split_6[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_32 (TFOpLambda)     (None, 49, 24, 32)   0           ['tf.split_6[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_24 (TFO  (None, 24, 49, 32)  0           ['tf.reshape_31[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_25 (TFO  (None, 24, 32, 49)  0           ['tf.reshape_32[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 24, 49, 49)   0           ['tf.compat.v1.transpose_24[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'tf.compat.v1.transpose_25[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 24, 49, 49)  0           ['lambda_12[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_4_block_2_mhsa_pos_emb (  (None, 24, 49, 49)  4056        ['tf.math.multiply_6[0][0]']     \n",
      " MultiHeadRelativePositionalEmb                                                                   \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_33 (TFOpLambda)     (None, 49, 24, 32)   0           ['tf.split_6[0][2]']             \n",
      "                                                                                                  \n",
      " stack_4_block_2_mhsa_attention  (None, 24, 49, 49)  0           ['stack_4_block_2_mhsa_pos_emb[0]\n",
      " _scores (Softmax)                                               [0]']                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_26 (TFO  (None, 24, 49, 32)  0           ['tf.reshape_33[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)             (None, 24, 49, 32)   0           ['stack_4_block_2_mhsa_attention_\n",
      "                                                                 scores[0][0]',                   \n",
      "                                                                  'tf.compat.v1.transpose_26[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_27 (TFO  (None, 49, 24, 32)  0           ['lambda_13[0][0]']              \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_34 (TFOpLambda)     (None, 7, 7, 768)    0           ['tf.compat.v1.transpose_27[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block_2_mhsa_output (D  (None, 7, 7, 768)   589824      ['tf.reshape_34[0][0]']          \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " stack_4_block_2_output (Add)   (None, 7, 7, 768)    0           ['stack_4_block_1_ffn_output[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'stack_4_block_2_mhsa_output[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block_2_ffn_preact_ln   (None, 7, 7, 768)   1536        ['stack_4_block_2_output[0][0]'] \n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block_2_ffn_1_conv (Co  (None, 7, 7, 3072)  2359296     ['stack_4_block_2_ffn_preact_ln[0\n",
      " nv2D)                                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_2_ffn_gelu (Acti  (None, 7, 7, 3072)  0           ['stack_4_block_2_ffn_1_conv[0][0\n",
      " vation)                                                         ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_2_ffn_2_conv (Co  (None, 7, 7, 768)   2359296     ['stack_4_block_2_ffn_gelu[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " stack_4_block_2_ffn_output (Ad  (None, 7, 7, 768)   0           ['stack_4_block_2_output[0][0]', \n",
      " d)                                                               'stack_4_block_2_ffn_2_conv[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 768)         0           ['stack_4_block_2_ffn_output[0][0\n",
      " 2D)                                                             ]']                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         769000      ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,285,602\n",
      "Trainable params: 23,273,954\n",
      "Non-trainable params: 11,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_base = coatnet.CoAtNet0(pretrained='imagenet',\n",
    "                          input_shape=(200, 200, 3))\n",
    "transfer_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " coatnet0 (Functional)       (None, 1000)              23285602  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               256256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,544,942\n",
      "Trainable params: 259,340\n",
      "Non-trainable params: 23,285,602\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(transfer_base)\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(class_num, activation='softmax'))\n",
    "transfer_base.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - ETA: 0s - loss: 1.8612 - accuracy: 0.5254\n",
      "Epoch 1: val_loss improved from inf to 1.44535, saving model to ./save_models/CoAtNet-7_12class/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3410s 3s/step - loss: 1.8612 - accuracy: 0.5254 - val_loss: 1.4453 - val_accuracy: 0.5847\n",
      "Epoch 2/5\n",
      "1148/1148 [==============================] - ETA: 0s - loss: 1.2604 - accuracy: 0.6376\n",
      "Epoch 2: val_loss improved from 1.44535 to 1.20839, saving model to ./save_models/CoAtNet-7_12class/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3361s 3s/step - loss: 1.2604 - accuracy: 0.6376 - val_loss: 1.2084 - val_accuracy: 0.6363\n",
      "Epoch 3/5\n",
      "1148/1148 [==============================] - ETA: 0s - loss: 1.0640 - accuracy: 0.6846\n",
      "Epoch 3: val_loss improved from 1.20839 to 1.09877, saving model to ./save_models/CoAtNet-7_12class/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3341s 3s/step - loss: 1.0640 - accuracy: 0.6846 - val_loss: 1.0988 - val_accuracy: 0.6634\n",
      "Epoch 4/5\n",
      "1148/1148 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.7118\n",
      "Epoch 4: val_loss improved from 1.09877 to 1.03410, saving model to ./save_models/CoAtNet-7_12class/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3357s 3s/step - loss: 0.9524 - accuracy: 0.7118 - val_loss: 1.0341 - val_accuracy: 0.6827\n",
      "Epoch 5/5\n",
      "1148/1148 [==============================] - ETA: 0s - loss: 0.8748 - accuracy: 0.7341\n",
      "Epoch 5: val_loss improved from 1.03410 to 0.98625, saving model to ./save_models/CoAtNet-7_12class/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_models/CoAtNet-7_12class/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3356s 3s/step - loss: 0.8748 - accuracy: 0.7341 - val_loss: 0.9863 - val_accuracy: 0.7031\n"
     ]
    }
   ],
   "source": [
    "#저장할 모델명(폴더명)\n",
    "model_name = 'CoAtNet-7_12class'\n",
    "\n",
    "#폴더생성\n",
    "if 'save_models' not in os.listdir(): os.mkdir('save_models')\n",
    "if model_name not in os.listdir('save_models'): os.mkdir('./save_models/{}'.format(model_name))\n",
    "#모델 저장 path\n",
    "path_checkpoint = \"./save_models/{}/\".format(model_name) \n",
    "#모델 저장 코드(weight만 저장)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5, restore_best_weights=True)\n",
    "modelckpt_callback = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_loss\", filepath=path_checkpoint, verbose=1, save_weights_only=False, save_best_only=True, save_format='tf')\n",
    "\n",
    "#fit\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0003)\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "history = model.fit(train_gen, validation_data=valid_gen, batch_size=batch_size, epochs=5, callbacks=[es_callback, modelckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f726c7d0dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('ACCURACY')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.legend(['train','validation'], loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 839s 2s/step - loss: 0.9692 - accuracy: 0.7038\n",
      "Test loss: 0.9692303538322449\n",
      "Test accuracy: 0.703839898109436\n"
     ]
    }
   ],
   "source": [
    "#저장된 최고 성능 모델 불러오기\n",
    "model_loaded = tf.keras.models.load_model(path_checkpoint)\n",
    "\n",
    "#test score 확인\n",
    "score = model_loaded.evaluate(test_gen) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
