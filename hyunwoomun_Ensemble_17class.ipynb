{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc73f7e-0dce-4be1-b593-51b2833b2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5614b3-56b9-4aa6-9901-329cb0ae2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Found 17340 images belonging to 17 classes.\n",
      "EffNetV2M_17class_0004.h5를 load 하고 있습니다.\n",
      "EffNetV2M_17class_0004.h5 load 완료.\n",
      "EffNetV2M_17class_0004.h5 model의 accuracy를 평가중입니다.\n",
      "542/542 [==============================] - 42s 77ms/step - loss: 0.5318 - accuracy: 0.8888\n",
      "EffNetV2M_17class_0004.h5 model accuracy 평가완료.\n",
      "EffNetV2M_17class_0004.h5 model의 predict를 진행중입니다.\n",
      "EffNetV2M_17class_0004.h5 model predict 완료.\n",
      "\n",
      "InceptionResNetV2_17class_0005.h5를 load 하고 있습니다.\n",
      "InceptionResNetV2_17class_0005.h5 load 완료.\n",
      "InceptionResNetV2_17class_0005.h5 model의 accuracy를 평가중입니다.\n",
      "542/542 [==============================] - 37s 69ms/step - loss: 0.8966 - accuracy: 0.8242\n",
      "InceptionResNetV2_17class_0005.h5 model accuracy 평가완료.\n",
      "InceptionResNetV2_17class_0005.h5 model의 predict를 진행중입니다.\n",
      "InceptionResNetV2_17class_0005.h5 model predict 완료.\n",
      "\n",
      "VGG16_17class_0002.h5를 load 하고 있습니다.\n",
      "VGG16_17class_0002.h5 load 완료.\n",
      "VGG16_17class_0002.h5 model의 accuracy를 평가중입니다.\n",
      "542/542 [==============================] - 24s 45ms/step - loss: 1.0140 - accuracy: 0.7724\n",
      "VGG16_17class_0002.h5 model accuracy 평가완료.\n",
      "VGG16_17class_0002.h5 model의 predict를 진행중입니다.\n",
      "VGG16_17class_0002.h5 model predict 완료.\n",
      "\n",
      "Xception_17class_0004.h5를 load 하고 있습니다.\n",
      "Xception_17class_0004.h5 load 완료.\n",
      "Xception_17class_0004.h5 model의 accuracy를 평가중입니다.\n",
      "542/542 [==============================] - 24s 44ms/step - loss: 0.9039 - accuracy: 0.8604\n",
      "Xception_17class_0004.h5 model accuracy 평가완료.\n",
      "Xception_17class_0004.h5 model의 predict를 진행중입니다.\n",
      "Xception_17class_0004.h5 model predict 완료.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    \n",
    "    batch_size = 32\n",
    "    target_size=(200,200)\n",
    "\n",
    "    gen = ImageDataGenerator(rescale=1/255.)\n",
    "    test_gen = gen.flow_from_directory('./data/test/', target_size=target_size, class_mode='categorical', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model_list = ['EffNetV2M_17class_0004.h5', 'InceptionResNetV2_17class_0005.h5', 'VGG16_17class_0002.h5', 'Xception_17class_0004.h5']\n",
    "    \n",
    "    model = []\n",
    "    acc = []\n",
    "    pred = []\n",
    "    \n",
    "    for i, mod in enumerate(model_list):\n",
    "        print('{}를 load 하고 있습니다.'.format(mod))\n",
    "        model.append(tf.keras.models.load_model('./save_models/{}'.format(mod)))\n",
    "        print('{} load 완료.'.format(mod))\n",
    "        \n",
    "        print('{} model의 accuracy를 평가중입니다.'.format(mod))\n",
    "        acc.append(model[i].evaluate(test_gen)[1]) # accuracy 저장 \n",
    "        print('{} model accuracy 평가완료.'.format(mod))\n",
    "        \n",
    "        print('{} model의 predict를 진행중입니다.'.format(mod))\n",
    "        pred.append(model[i].predict(test_gen)) # predict list 저장\n",
    "        print('{} model predict 완료.\\n'.format(model_list[i]))\n",
    "        \n",
    "    w_pred = np.zeros_like(pred[0]) #weighted pred 저장\n",
    "    for i in range(len(model)):\n",
    "        w_pred += (pred[i]*acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc67078-e0a7-4109-bc67-7b6c8c58f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_img : 17340 \t steps : 541\n"
     ]
    }
   ],
   "source": [
    "#test gen의 image와 label 추출\n",
    "n_img = test_gen.n\n",
    "steps = n_img//batch_size\n",
    "print(f'n_img : {n_img} \\t steps : {steps}')\n",
    "\n",
    "imgs, labels = [], []\n",
    "for i in range(steps):\n",
    "    a, b = test_gen.next()\n",
    "    imgs.extend(a)\n",
    "    labels.extend(b)\n",
    "\n",
    "imgs = np.asarray(imgs)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ede5baa8-684c-48b7-8ed6-5a7dfd92f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9905번째 사진 class 예측\n",
      "\n",
      "0 0 70 0 16 0 0 0 0 0 3 0 0 8 0 0 0 \tacc: 88.88 %\n",
      "0 0 0 0 0 0 0 0 0 63 0 24 0 8 0 0 1 \tacc: 82.42 %\n",
      "0 0 0 0 0 0 0 0 0 96 0 0 0 3 0 0 0 \tacc: 77.24 %\n",
      "0 0 0 0 0 0 87 0 0 0 1 7 0 0 0 0 1 \tacc: 86.04 %\n",
      "\n",
      "Ensemble\n",
      "0 0 62 1 14 0 75 0 0 126 4 26 0 17 0 0 2\n",
      "Ground Truth\n",
      "0 0 0 0 0 0 0 0 0 100 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "#난수번째 class 예측\n",
    "k = np.random.randint(0,n_img-1)\n",
    "print(f'{k+1}번째 사진 class 예측\\n')\n",
    "print(*[int(i) for i in pred[0][k]*100], '\\tacc:',round(acc[0]*100,2),'%')\n",
    "print(*[int(i) for i in pred[1][k]*100], '\\tacc:',round(acc[1]*100,2),'%')\n",
    "print(*[int(i) for i in pred[2][k]*100], '\\tacc:',round(acc[2]*100,2),'%')\n",
    "print(*[int(i) for i in pred[3][k]*100], '\\tacc:',round(acc[3]*100,2),'%')\n",
    "print('\\nEnsemble')\n",
    "print(*[int(i) for i in w_pred[k]*100])\n",
    "print('Ground Truth')\n",
    "print(*[int(i) for i in labels[k]*100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "717dd7d2-d5f2-426f-8dfe-21ebc0fb2fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy 91.74 %\n"
     ]
    }
   ],
   "source": [
    "true=0\n",
    "for i in range(len(imgs)):\n",
    "    if np.argmax(w_pred[i])==np.argmax(labels[i]):\n",
    "        true+=1\n",
    "        \n",
    "print('Ensemble accuracy',round(true/n_img*100,2),'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
